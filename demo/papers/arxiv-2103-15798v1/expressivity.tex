% !TEX root = main.tex

\section{Expressivity Results}\label{app:expressivity}

Here we collect results on the expressivity of the set of $\XD$-operations.
For simplicity, our results will be in the following single-dimensional ($N=1$) setting:
\begin{Set}\label{app:set:single}
	Let input space $\X=\R^{c\times n}$ for input size $n\in\N$ a power of two and channel count $c\in\N$ be identical to the output space, and let the parameter space be $\W=\R^{c\times c\times k}$ for filter size $k\in[n]$.
\end{Set}
It is straightforward to extend the results to multiple dimensions using Kronecker products and to input sizes other than powers of two using padding.
Note that all of our results will also assume a circular padded domain.

\subsection{Convolutions}
\begin{Def}\label{app:def:conv}
	A {\bf convolution} in Setting~\ref{app:set:single} with filter size $k$, dilation $d\in[\lfloor\frac{n-1}{k-1}\rfloor]$, stride $s\in[n-1]$, and channel groups described by a matrix $\*B\in\{0,1\}^{n\times n}$ s.t. $\*B_{[i,j]}=1$ if channels $i$ and $j$ are in the same group and 0 otherwise is a parameterizable operation that for any weight $\*w\in\W$ outputs a function mapping every $\*x\in\X$ to
	\begin{equation}
	\frac1n
	\begin{pmatrix}
	\diag(\atr_s(\underline{\1_{\lceil\frac ns\rceil}}))\sum\limits_{j=1}^c\*B_{[1,j]}\*F_n^{-1}\diag(\*F_n\atr_d(\underline{\*w_{[1,j]}}))\*F_n\*x_{[j]}\\
	\vdots\\
	\diag(\atr_s(\underline{\1_{\lceil\frac ns\rceil}}))\sum\limits_{j=1}^c\*B_{[c,j]}\*F_n^{-1}\diag(\*F_n\atr_d(\underline{\*w_{[c,j]}}))\*F_n\*x_{[j]}
	\end{pmatrix}
	\end{equation}
	where $\*F_n\in\C^{n\times n}$ is the $n\times n$ DFT and $\atr_d:\R^n\mapsto\R^n$ is an atrous permutation of a vector that is equivalent to multiplication by some permutation matrix $\*P_d\in\{0,1\}^{n\times n}$.
	We will use $\Conv_k$ to denote the case of $d=1$, $s=1$, and $\*B=\1_{c\times c}$.
\end{Def}
\begin{Clm}\label{app:clm:conv}
	All multi-channel convolutions of the form given in Definition~\ref{app:def:conv} are contained in the search space of XD-operations of depth $(1,3,1)$.
\end{Clm}
\begin{proof}
	Setting the architecture parameters to be $\*K=\diag(\atr_s(\underline{\1_{\lceil\frac ns\rceil}}))\*F_n^{-1}$, $\*L=\*F_n\*P_d$, $\*M=\*F_n$, $\*b=\0_n$, and $\*C=\*B$, and noting that (a) the DFT and its inverse are both depth 1 K-matrices, (b) multiplying a K-matrix by a diagonal matrix is another K-matrix of the same depth, and (c) permutation matrices are K-matrices of depth 2 yields the result.
	These three facts are due to \citet{dao2020kaleidoscope}.
\end{proof}
\begin{Rem}
	Note that for the case of dilation $d=1$ the result in Claim~\ref{app:clm:conv} holds with depth $\1_3$.
\end{Rem}

\subsection{Parameter-Free Operations}

\begin{Def}\label{app:def:skip}
	The {\bf skip-connection} in Setting~\ref{app:set:single} is parameterizable operation that outputs a function mapping every $\*x\in\X$ to itself.
	The {\bf zero-operation} in Setting~\ref{app:set:single} is parameterizable operation that outputs a function mapping every $\*x\in\X$ to $\0_{c\times n}$.
\end{Def}
\begin{Clm}\label{app:clm:skip}
	The skip-connection and zero-operation are both contained in the search space of XD-operations of depth $\1_3$.
\end{Clm}
\begin{proof}
	For both set the architecture parameters to be $\*K=\*F_n^{-1}$, $\*L=\0_{n\times n}$, $\*M=\*F_n$, and $\*C=\*I_c$.
	To obtain the skip-connection set $\*b=\1_n$;
	to obtain the zero-operation set $\*b=\0_n$.
\end{proof}

\begin{Def}\label{app:def:avgp}
	An {\bf average pooling} operation in Setting~\ref{app:set:single} with filter size $k$, dilation $d\in[\lfloor\frac{n-1}{k-1}\rfloor]$, and stride $s\in[n-1]$ is parameterizable operation outputs a function mapping every $\*x\in\X$ to the output of a convolution (as in Definition~\ref{app:def:conv}) with the same filter size, dilation, and stride, channel groups described by $\*B=\*I_c$, and filters $\*w_{[j,j]}=\1_k/k~\forall~j\in[c]$.
\end{Def}
\begin{Clm}\label{app:clm:avgp}
	All average pooling operations are contained in the search space of XD-operations of depth $\1_3$.
\end{Clm}
\begin{proof}
	Setting the architecture parameters to be $\*K=\diag(\atr_s(\underline{\1_{\lceil\frac ns\rceil}}))\*F_n^{-1}$, $\*L=\0_{n\times n}$, $\*M=\*F_n$, $\*b=\atr_d(\underline{\1_k/k})$, and $\*C=\*I_c$ and noting that (a) the DFT and its inverse are both depth 1 K-matrices and (b) multiplying a K-matrix by a diagonal matrix of the same depth is another K-matrix of the same depth yields the result.
\end{proof}

\subsection{Compositions with Multiplication by a Fixed K-Matrix}

\begin{Def}\label{app:def:lin}
	A {\bf fixed linear operation} $\Lin_{\*A}$ in Setting~\ref{app:set:single} with fixed matrix $\*A\in\R^{n\times n}$ is a parameterizable operation that outputs a function mapping every $\*x\in\X$ to $\Lin_{\*A}(\*w)(\*x)=\begin{pmatrix}\*Ax_{[1]}&\cdots&\*Ax_{[c]}\end{pmatrix}^T$.
	For example, $\Lin_{\*I_c}=\Id$.
\end{Def}

\begin{Def}\label{app:def:composition}
	Let $\Op_1$ and $\Op_2$ be two parameterizable operations in Setting~\ref{app:set:single} with $\X$.
	Then for any weight $\*w\in\W$ their {\bf composition} $\Op_1\circ\Op_2$ outputs the parameterized function $\Op_1(\*w)\circ\Op_2(\*w)$.
\end{Def}

\begin{Clm}\label{app:clm:composition}
	Let $\Op$ be a parameterizable operation in Setting~\ref{app:set:single} that is contained in the set of XD-operations of some depth $\*d\in\N^3$ and let $\*A$ be a K-matrix of depth $d'$.
	Then $\Op\circ\Lin_{\*A}$ is contained in the set of XD-operations of depth $(\*d_{[1]},\*d_{[2]},\*d_{[3]}+d')$ and $\Lin_{\*A}\circ\Op$ is contained in the set of XD-operations of depth $(\*d_{[1]}+d',\*d_{[2]},\*d_{[3]})$.
\end{Clm}
\begin{proof}
	Let $\*K$ and $\*M$ be the first and last K-matrices of the representation of $\Op$ as an XD-operation, which thus have depth at most $\*d_{[1]}$ and $\*d_{[3]}$, respectively.
	Then the representation of $\Op\circ\Lin_{\*A}$ as an XD-operation is the same except with depth $\*d_{[3]}+d'$ K-matrix $\*M\*A$ as the last K-matrix, and similarly the representation of $\Lin_{\*A}\circ\Op$ as an XD-operation is the same except with depth $\*d_{[1]}+d'$ K-matrix $\*A\*K$ as the first K-matrix.
\end{proof}

\subsection{Other Named Operations}

\begin{Def}
	Suppose we have a fixed $n$-node graph with adjacency matrix $\*A$ and degree matrix $\*D$, and let $\hat{\*A}$ and $\hat{\*D}$ be the adjacency and degree matrices, respectively, of the same graph but with added self-loops.
	Then regular {\bf graph convolution} \citep{kipf2017gcn} in Setting~\ref{app:set:single} with $k=1$ is a parameterizable operation that for any weight $\*W\in\W$ outputs a function mapping every $\*X\in\X$ to $\hat{\*D}^{-\frac12}\hat{\*A}\hat{\*D}^{-\frac12}\*x^T\*w$ and the {\bf diffusion graph convolution} \citep{li2018dcrnn} in Setting~\ref{app:set:single} with $k=1$ is a parameterizable operation that for any weight $\*W\in\W$ outputs a function mapping every $\*X\in\X$ to $\*D^{-1}\*A\*x^T\*w$.
\end{Def}
\begin{Clm}
	Suppose $\*A$ and $\hat{\*A}$ can be represented by K-matrices of depth $d$ and $\hat d$, respectively.
	Then the corresponding graph convolution is contained in the search space of XD-operations of depth $(1,1,\hat d+1)$ and the corresponding diffusion graph convolution in that of depth $(1,1,d+1)$.
\end{Clm}
\begin{proof}
	For any $\*G\in\R^{n\times n}$ we have  $\*G\*x^T\*w=\Lin_{\*G}(\*w)(\*x)\*w=\Conv_1(\*w)(\Lin_{\*G}(\*w)(\*x))=(\Conv_1\circ\Lin_{\*G})(\*w)(\*x)$.
	The result follows by Claims~\ref{app:clm:conv} and~\ref{app:clm:composition}, the fact that a K-matrix multiplied by a diagonal matrix is another K-matrix of the same depth, and by substituting $\*G=\hat{\*D}^{-\frac12}\hat{\*A}\hat{\*D}^{-\frac12}$ (for graph convolution) or $\*G=\*D^{-1}\*A$ (for diffusion graph convolution).
\end{proof}
\begin{Rem}
	Note that the above claim is meaningful because adjacency matrices of realistic graphs are usually sparse and sparse matrices can be efficiently represented as K-matrices \citep{dao2020kaleidoscope}.
\end{Rem}

\begin{Def}
	A {\bf Fourier neural operator} (FNO) \citep{li2021fno} in Setting~\ref{app:set:single} with even $k$ and thus $k/2$ modes is a parameterizable operation that for any weight $\*w\in\W$ outputs a function mapping every $\*x\in\X$ to 
	\begin{equation}
		\begin{pmatrix}
		\Real\left(\sum_{j=1}^c\*F_n^{-1}\diag(\begin{pmatrix}\*w_{[1,j,1:k/2]}+i\*w_{[1,j,k/2+1:k]}&\0_{n-k/2}\end{pmatrix}^T)\*F_n\*x_{[j]}\right)\\
		\vdots\\
		\Real\left(\sum_{j=1}^c\*F_n^{-1}\diag(\begin{pmatrix}\*w_{[c,j,1:k/2]}+i\*w_{[c,j,k/2+1:k]}&\0_{n-k/2}\end{pmatrix}^T)\*F_n\*x_{[j]}\right)
		\end{pmatrix}
	\end{equation}
\end{Def}
\begin{Clm}\label{app:clm:fno}
	The FNO with $k/2$ modes is contained in the search space of XD-operations of depth $(1,4,1)$.
\end{Clm}
\begin{proof}
	Setting the architecture parameters to be $\*K=\*F_n^{-1}$, $\*L\in\C^{n\times n}$ the $n$-sparse matrix mapping $\underline{\*w}$ to $\begin{pmatrix}\*w_{[1,j,1:k/2]}+i\*w_{[1,j,k/2+1:k]}&\0_{n-k/2}\end{pmatrix}^T$, $\*M=\*F_n$, $\*b=\0_n$, and $\*C=\1_{c\times c}$, and noting that an $n$-sparse matrix is a depth-4 K-matrix \citep{dao2020kaleidoscope} yields the result.
\end{proof}
\begin{Rem}
	If we allow the parameter space in Setting~\ref{app:set:single} to be complex then the FNO with all $k$ modes will be contained in the search space of XD-operations of depth $\1_3$.
\end{Rem}

\begin{Def}
	A {\bf depthwise-separable convolution} in Setting~\ref{app:set:single} with filter size $k$ but with parameter space $\W=\R^{c\times k}\times\R^{c\times c}$ is a parameterizable operation that for any weight $\*w\in\W$ outputs $\Conv_1(\*w_{[2]})\circ\Conv_{k,\*I_c}(\*w_{[1]})$, where $\Conv_{k,\*I_c}$ denotes the convolution in Definition~\ref{app:def:conv} with $\*B=\*I_c$.
\end{Def}
\begin{Rem}
	Since both $\Conv_1$ and $\Conv_{k,\*I_c}$ are XD-operations, by definition depthwise-separable convolutions are contained in the search space of composed XD-operations, which by Claim~\ref{app:clm:skip} also contains all of the above operations.
\end{Rem}